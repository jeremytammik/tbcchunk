[
  {
    "original_filename": "1536_q4r4",
    "header_text": "Introduction",
    "local_header_href": "#introduction",
    "chunk_text": "<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"bc.css\">\n<script src=\"run_prettify.js\" type=\"text/javascript\"></script>\n<!--\n<script src=\"https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js\" type=\"text/javascript\"></script>\n-->\n</head>\n\n<!---\n\nRAQAS\nraq\nhowtorevitapi\nhowtorvtapi\nhowtorvt\nrpqas\nqarp\nq4r4\nr4q4\n\n- blog on elasticsearch\n\n\n #RevitAPI @AutodeskRevit #aec #bim #dynamobim @AutodeskForge http://bit.ly/devdays2016online\n\nI am back from my short vacation and raring to go again.\nI checked in to the Revit API discussion forum today, of course.\nI am much more interested in implementing a question answering system or QAS for the Revit API, though.\nNow I finally had a chat with a real human being who put me on the right track to getting started for real\n&ndash; The Revit API question answering system Q4R4\n&ndash; Three steps towards implementing a QAS\n&ndash; Obsolete pre-Sacha notes...\n\n-->"
  },
  {
    "original_filename": "1536_q4r4",
    "header_text": "Q4R4 &ndash; Plans for the Revit API Question Answering System",
    "local_header_href": "#q4r4-ndash-plans-for-the-revit-api-question-answering-system",
    "chunk_text": "### Q4R4 &ndash; Plans for the Revit API Question Answering System\n\nI am back from my short vacation and raring to go again.\n\nI checked in to\nthe [Revit API discussion forum](http://forums.autodesk.com/t5/revit-api-forum/bd-p/160) today, of course.\n\nI am much more interested in doing more to implement a question answering system or QAS for the Revit API, though.\n\nI repeatedly mentioned my explorations into the very hip subject of machine learning with that goal in mind.\n\nNow I finally had a chat with a real human being AI expert, a fellow Autodesk employee, who put me on the right track to getting started for real:\n\n- [The Revit API question answering system Q4R4](#2)\n- [Three steps towards implementing a QAS](#3)\n- [Obsolete pre-Sacha notes](#4)"
  },
  {
    "original_filename": "1536_q4r4",
    "header_text": "<a name=\"2\"></a>The Revit API Question Answering system Q4R4",
    "local_header_href": "#a-name2athe-revit-api-question-answering-system-q4r4",
    "chunk_text": "#### <a name=\"2\"></a>The Revit API Question Answering system Q4R4\n\nI last mentioned this topic when asking [quo vadis Revit API QAS?](http://thebuildingcoder.typepad.com/blog/2017/01/family-category-and-two-energy-model-types.html#8)\n\nAt the time, I was searching for an expert to talk with and get some real hands-on advice from before getting started for real.\n\nThis person materialised in the form of Autodesk colleague Sacha Leprêtre, AI expert in Montreal.\n\nBefore explaining what I learned from our conversation, I'll mention the name that I came up with for this:\n\n`Q4R4`, a more unique acronym than QARA, short for *Question Answering system for Revit API*."
  },
  {
    "original_filename": "1536_q4r4",
    "header_text": "<a name=\"3\"></a>Three steps towards implementing a QAS",
    "local_header_href": "#a-name3athree-steps-towards-implementing-a-qas",
    "chunk_text": "#### <a name=\"3\"></a>Three steps towards implementing a QAS\n\nSacha consulted with a colleague before our chat and came up with the following advice, in three steps:\n\n1. Specialised search.\n2. Machine learning.\n3. Deep learning.\n\nIt is useless diving into deep learning before first implementing and measuring the results of other specialised search approaches, optionally enhanced and optimised using machine learning techniques.\n\nThe latter can only be applied after the former is up and running, and deep learning makes no sense until the first two steps have been completed.\n\nIn summary:\n\n1. The first thing to do is to customise a search engine.\n[Elasticsearch](https://www.elastic.co) also includes [NLP](https://en.wikipedia.org/wiki/Natural_language_processing).\nIt is available in several languages, Java based, using [Lucene](https://lucene.apache.org), a state of the art search engine.\nIt is driven using a REST API, supports semantic analysis. Use this to create an own extractor for the Revit API domain information extraction.\n\n2. Second step: optimise the searches using machine learning.\nThis is not the same as deep learning.\nMany algorithms exist, e.g., random forest, xg boost, etc.\nYou need samples to test and enhance your approach.\n\n3. Third step: you may want to apply deep learning techniques to further enhance the solution.\nDeep learning techniques need to consume a lot of data to bring results.\n\nHere is the French original of the advice provided by Sasha's unnamed friend:\n\n1. Dans un premier temps, une approche par moteur de recherche spécialisé est probablement la plus efficace, la moins risquée et la plus rapide à mettre en œuvre.\nCela peut constituer un plan de contingence (contingency plan) ou une référence (baseline) à l'utilisation d'un système plus sophistiqué faisant appel à l'apprentissage statistique conventionnel voire à de l'apprentissage profond.\nJe verrais très bien un projet réalisé par étapes.\n\n2. Algorithmes d'apprentissage statistique conventionnels:\nCe qui marche le mieux en apprentissage statistique demeure l'apprentissage supervisé à partir d'exemples/observations étiquetés.\nC'est encore plus vrai pour l'apprentissage profond, où l'apprentissage non-supervisé relève davantage de la recherche que du domaine des applications.\nAvec des algorithmes d'apprentissage conventionnels, les meilleurs étant les méthodes ensemblistes (explications plus bas), ont peut obtenir de bons résultats avec quelques centaines d'exemples étiquetés (labeled samples). \nLes algos ensemblistes sont des méta-algorithmes où l'on combine les résultats d'un ensemble de classificateurs simples.\nLes plus connues sont le bagging (ré-échantillonnage et vote ou moyenne) et le boosting (pondération des classificateurs).\nConcrètement on parle de forêt d'arbres aléatoires (Random Forest), de Gradient Tree Boosting et surtout de XGBoost (Extreme Gradient Boosting).\n\n3. Apprentissage profond: \nLe principal obstacle pour l'utilisation de l'apprentissage profond est de disposer de suffisamment de données.\nTypiquement, la règle du pouce est qu'un algorithme d'apprentissage profond supervisé atteindra des performances acceptables avec environ 5000 exemples étiquetés (labeled samples) par question et dépassera la performance humaine lorsqu'il sera entraîné avec un ensemble de données contenant au moins 10 millions d'exemples / observations.\nDans le cas d'un nombre insuffisants de données, il existe en gros quatre solutions potentielles. L'étiquetage « par la foule » (crowdsourcing), l'apprentissage semi-supervisé (étiquetage automatique ou semi-automatique) à partir de jeux de données importants mais non étiquetés, l'amplification de données (data augmentation) où l'on génère automatiquement des variantes des données disponibles et le transfert d'apprentissage (learning transfer) qui consiste à ajouter à un réseau de neurones profonds pré-entraînés sur un énorme corpus générique une couche applicative spécifique.\n\nHere is my translation of that:\n\n1. Initially, a specialized search engine approach is probably the most efficient, the least risky and the fastest to implement. This can be a contingency plan or provide a base for a more sophisticated system involving conventional statistical learning or even deep learning. I would see a project realized in stages.\n\n2. Conventional statistical learning algorithms:\nWhat works best in statistical learning remains supervised learning from labelled examples / observations.\nThis is even truer for deep learning, where unsupervised learning is more about research than application.\nWith conventional learning algorithms, the best ones are the set methods (explained below), which may provide good results with just a few hundred labelled samples.\nSet algorithms are meta-algorithms where we combine the results of a set of simple classifiers.\nThe best known are bagging (resampling and voting or average) and boosting (weighting of classifiers).\nConcretely, we speak about random forests of trees (Random Forest), Gradient Tree Boosting and especially XGBoost (Extreme Gradient Boosting).\n\n3. Deep learning:\nThe main obstacle to the use of deep learning is to have sufficient data.\nTypically, the rule of thumb is that a supervised deep learning algorithm will achieve acceptable performance with about 5000 labelled samples per question and will exceed human performance when trained with a data set containing at least 10 million examples / observations.\nIn the case of insufficient data, there are roughly four potential solutions.\nCrowdsourcing, semi-supervised learning (automatic or semi-automatic labelling) from large but unlabelled datasets, data augmentation by automatically generating variants of the available data and learning transfer, which consists in adding a specific application layer to a network of deep neurons pre-trained on a huge generic corpus.\n\nIn all cases, the most important point remains creating a good knowledge base:\nit can consist of just documents, knowing how to connect them, unstructured document content, how are they related.\n\nThe elastic search engine can do this.\n\nThe UI is another challenge, e.g., when to display a result, display portion of text already, not only links.\n\nCreating an ontology is tough, and that is not what works well.\n\nBetter: dictionaries, simple bag of words related to a topic.\n\nFirst step: create a search engine and ask the system after indexing all words in the content, ask for frequencies of terms, analyse what you have, understand the content.\nBuild on NLP techniques, develop your own extractor.\nIt creates topics based on bag of words.\nUse machine learning to cluster words.\nBut first just implement manual search.\n\nMany thanks to Sacha and his friend for their invaluable advice!\n\nAfter the chat with him, I looked more at topics involving NLP and searching, e.g.,\n[semantic search with NLP and Elasticsearch](http://stackoverflow.com/questions/8772692/semantic-search-with-nlp-and-elasticsearch),\n[ConceptNet](https://blog.conceptnet.io/2016/11/03/conceptnet-5-5-and-conceptnet-io) and\nthe [maui-indexer](https://code.google.com/archive/p/maui-indexer).\n\nOn Sacha's recommendation, I listened to one of the free online courses on NLP by Prof. Dan Jurafsky and Chris Manning,\nexplaining [what question answering is](https://youtu.be/DAHZPL6voc4):\n\n<center>\n<iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/DAHZPL6voc4?rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n</center>\n\nAn interesting way to go might also be to integrate Q4R4 \nwith [DuckDuckGo](https://en.wikipedia.org/wiki/DuckDuckGo)\n(cf. [DuckDuckHack](https://docs.duckduckhack.com)) or some other Internet search engine.\n\n<center>\n<img src=\"img/duckduckgo.png\" alt=\"DuckDuckGo\" width=\"100\"/>\n</center>"
  },
  {
    "original_filename": "1536_q4r4",
    "header_text": "<a name=\"4\"></a>Obsolete Pre-Sacha Notes",
    "local_header_href": "#a-name4aobsolete-pre-sacha-notes",
    "chunk_text": "#### <a name=\"4\"></a>Obsolete Pre-Sacha Notes\n\nBefore our chat and deciding to get started with Elasticsearch and the implementation of step 1 above, I was still browsing through reams of other interesting stuff that all seems useless now.\n\nStill, here are my notes to self on all that:\n\n- [Amazon AI](https://aws.amazon.com/amazon-ai) &ndash; Autodesk signed a contract with Amazon, so we might be able to tap into their resources.\n    - Amazon Lex -- conversational interface powered by the same deep learning technologies as Alexa\n    - Amazon Rekognition -- deep learning-based image recognition\n    - Amazon Polly -- turn text into lifelike speech using deep learning\n    - Amazon Machine Learning -- a scalable machine learning service for developers.\n    - I might be able to use lex + polly\n- [My post on adsk #tech-machine-learning](https://autodesk.slack.com/archives/tech-machine-learning/p1485442345000168)\n- [Finding Similar Questions in Large Question and Answer Archives](http://ciir.cs.umass.edu/pubfiles/ir-442.pdf) [^](/a/doc/deep_learning/find_similar_question/ir-442.pdf))\n- [TensorFlow for Machine Intelligence book](https://bleedingedgepress.com/tensor-flow-for-machine-intelligence/)\n- [Deep Learning With Python](https://machinelearningmastery.com/deep-learning-with-python) by Jason Brownlee &ndash; develop deep learning models on Theano and TensorFlow using the Python deep learning library Keras.\n- [Google Developers Codelabs](https://codelabs.developers.google.com/)\n- [TensorFlow Playground](http://playground.tensorflow.org)\n- [Tensorflow for poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html#0) tutorial\n- [Tensorflow and deep learning withut a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/index.html?index=..%2F..%2Findex#0)\n- [TensorFlow in 5 Minutes](https://www.youtube.com/watch?v=2FmcHiLCwTU)\n- [MemDump machine learning blog on TensorFlow](http://www.memdump.io/tag/tensorflow/)\n- [Inside Libratus, the Poker AI That Out-Bluffed the Best Humans](https://www.wired.com/2017/02/libratus/)\n- [Microsoft Bot framework](https://dev.botframework.com): [yourface](https://bots.botframework.com/bot?id=yourface), [Bot builder SDK](https://github.com/Microsoft/BotBuilder)\n- [Top-down learning path: Machine Learning for Software Engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers)\n- [Google releases TensorFlow 1.0 with new machine learning tools](http://venturebeat.com/2017/02/15/google-releases-tensorflow-1-0-with-new-machine-learning-tools/)\n- [Google open-sources SyntaxNet, a natural-language understanding library (NLU) for TensorFlow](http://venturebeat.com/2016/05/12/google-open-sources-syntaxnet-a-natural-language-understanding-library-for-tensorflow/)\n- [SyntaxNet: Neural Models of Syntax](https://github.com/tensorflow/models/tree/master/syntaxnet)\n- [Awesome &ndash; Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)\n- [Adding Tensorflow module to Fusion 360](http://ndesign.co/2017/03/08/adding-tensorflow-module-to-fusion-360/), a super minimal test addition of the basic TensorFlow Python module to Fusion 360\n\n\nEnough of that for now.\n\nI can't wait to get started exploring Elasticsearch in more depth.\n\nHere's why, quoted from the [Elasticsearch guide getting started chapter](https://www.elastic.co/guide/en/elasticsearch/guide/current/search.html):\n\n> Elasticsearch as a simple NoSQL-style distributed document store. We can throw JSON documents at Elasticsearch and retrieve each one by ID. But the real power of Elasticsearch lies in its ability to make sense out of chaos &ndash; to turn Big Data into Big Information.\n\nThat sound like just the ticket to feed all the relevant Revit API information sources into Q4R4, make sense out of stuff, and create a really useable knowledge base for the community."
  }
]